<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Propositional Logic"><meta property="og:title" content="Propositional Logic" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://pantelis.github.io/cs-gy-6613-spring-2020/docs/lectures/planning/propositional-logic/" />

<title>Propositional Logic | CS-GY-6613 Spring 2020</title>
<link rel="icon" href="/cs-gy-6613-spring-2020/favicon.png" type="image/x-icon">


<link rel="stylesheet" href="/cs-gy-6613-spring-2020/book.min.ccf2e3f83640a9c2266488b947be5b9ddbdea671b0de107d1d379f1d6f6d0408.css" integrity="sha256-zPLj&#43;DZAqcImZIi5R75bndvepnGw3hB9HTefHW9tBAg=">


<script defer src="/cs-gy-6613-spring-2020/en.search.min.629aa1b1a703c264d11fc928b164e473b92bf9691a23429507ee6cf19dbcf2d9.js" integrity="sha256-YpqhsacDwmTRH8kosWTkc7kr&#43;WkaI0KVB&#43;5s8Z288tk="></script>

<link rel="alternate" type="application/rss+xml" href="http://pantelis.github.io/cs-gy-6613-spring-2020/docs/lectures/planning/propositional-logic/index.xml" title="CS-GY-6613 Spring 2020" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body>
  <input type="checkbox" class="hidden" id="menu-control" />
  <main class="container flex">
    <aside class="book-menu">
      
  <nav>
<h2 class="book-brand">
  <a href="/cs-gy-6613-spring-2020"><img src="/cs-gy-6613-spring-2020/tandon_long_black.png" alt="Logo" /><span>CS-GY-6613 Spring 2020</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>





  

  
  





 
  
    




  
  <ul>
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/syllabus/" >
      Syllabus
  </a>

</li>
      
    
      
        

  <li >
    
      <span>Lecture 1 - Introduction to AI</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ai-intro/course-introduction/" >
      Course Introduction
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ai-intro/systems-approach/" >
      A systems approach to AI
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Systems Approach Slides</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ai-intro/ai-pipelines/" >
      The Way of Working in AI
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Ai Pipelines Slides</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ai-intro/agents/" >
      Intelligent Agents and Representations
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Agents Slides</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/learning-problem/" >
      Lecture 2a - The Learning Problem
  </a>


    

    




  
  <ul>
    
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Lecture 2b - Regression</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/regression/linear-regression/" >
      Linear Regression
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/" >
      Lecture 2c - Linear Classification
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/knn/" >
      k-Nearest Neighbors (kNN) Classification
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/perceptron/" >
      The Perceptron
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/logistic-regression/" >
      Logistic Regression
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/kernels/" >
      Kernels and the Kernel Trick
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/clustering/" >
      K-means Clustering
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/svm/" >
      Support Vector Machines
  </a>


    

    




  
  <ul>
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/svm/face-recognition/" >
      Face Recognition - SVM Case Study
  </a>

</li>
      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/svm/mnist/" >
      MNIST Classification - SVM Case Study
  </a>

</li>
      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/svm/iris/" >
      Iris Classification - SVM Case Study
  </a>

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/decision-trees/" >
      Decision Trees
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/random-forests/" >
      Random Forests
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/dnn/" >
      Lecture 3 - Deep Neural Networks
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/dnn/backprop-intro/" >
      Introduction to Backpropagation
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/dnn/backprop-dnn/" >
      Backpropagation in Deep Neural Networks
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Regularization in Deep Neural Networks</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/dnn/fashion-mnist-case-study/" >
      Fashion MNIST Case Study
  </a>

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Lecture 4a - Convolutional Neural Networks</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/cnn/cnn-intro/" >
      Introduction to Convolutional Neural Networks
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/cnn/cnn-arch/" >
      CNN Architectures
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/cnn/cnn-sizing/" >
      CNN Sizing
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Attention Mechanisms in CNNs</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/rnn/" >
      Lecture 4b - Sequences and Recurrent Neural Networks (RNN)
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/rnn/simple-rnn/" >
      Simple RNNs and their Backpropagation
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/rnn/lstm/" >
      The Long Short-Term Memory (LSTM) Cell Architecture
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Lecture 5 - Scene Understanding</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/scene-understanding/scene-understanding-intro/" >
      Introduction to Scene Understanding
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/scene-understanding/feature-extraction-resnet/" >
      Feature Extraction via Residual Networks
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/scene-understanding/object-detection/" >
      Object Detection
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Semantic Segmentation</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Lecture 6 - Probabilistic Graphical Models</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/pgm/pgm-intro/" >
      Introduction to Probabilistic Reasoning
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/pgm/bayesian-inference/" >
      Inference in Graphical Models
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/pgm/recursive-state-estimation/" >
      Recursive State Estimation
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/pgm/localization/" >
      Localization and Tracking
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/planning/" >
      Lecture 7 - Planning
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/planning/propositional-logic/"  class="active">
      Propositional Logic
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/planning/logical-agents/" >
      Logical Agents
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/planning/classical-planning/" >
      Classical Planning
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/planning/search/" >
      Planning with Search
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Autonomous Agent Planning Application</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Online Prediction</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Behavioral Planning</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Trajectory Generation</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Lecture 8 - Markov Decision Processes</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/mdp/mdp-slides/" >
      Mdp Slides
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>The Agent - Environment Interface</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/projects/" >
      Projects
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/projects/imu-classification/" >
      Project 1 - Surface Type Classification
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/projects/continuous-learning/" >
      Project 2 - Continual Learning for Robotic Perception
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/projects/semantic-code-search/" >
      Project 3 - Semantic Code Search
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/projects/env/" >
      Your Programming Environment
  </a>

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Background - Math for ML</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-math/linear-algebra/" >
      Linear Algebra for Machine Learning
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-math/optimization/" >
      Optimization and Stochastic Gradient Descent
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-math/probability/" >
      Probability and Information Theory Basics
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-math/netflix/" >
      The Netflix Prize and Singular Value Decomposition
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/" >
      Background - ML Frameworks
  </a>


    

    




  
  <ul>
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/numpy-pandas/" >
      Numerical Python (Numpy/Scipy and Pandas) Tutorials
  </a>

</li>
      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/tensorflow-introduction/" >
      Introduction to Tensorflow
  </a>

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Drafts</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Constraint Satisfaction Programming</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Transfer Learning</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Generative Modeling and Continuous Variational Auto Encoders (VAE)</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Natural Language Processing</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Creating Reasonable Embeddings</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
  </ul>
  



  











</nav>




  <script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script>


 
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/cs-gy-6613-spring-2020/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Propositional Logic</strong>

  <label for="toc-control">
    <img src="/cs-gy-6613-spring-2020/svg/toc.svg" class="book-icon" alt="Table of Contents" />
  </label>
</div>


  
    <input type="checkbox" class="hidden" id="toc-control" />
    <aside class="hidden clearfix">
      
  <nav id="TableOfContents">
  <ul>
    <li><a href="#propositional-logic">Propositional Logic</a>
      <ul>
        <li><a href="#world-models">World Models</a></li>
        <li><a href="#model-checking-inference">Model-Checking Inference</a></li>
        <li><a href="#propositional-logic-syntax">Propositional Logic Syntax</a></li>
        <li><a href="#propositional-logic-semantics">Propositional Logic Semantics</a></li>
        <li><a href="#inference-example">Inference Example</a></li>
      </ul>
    </li>
  </ul>
</nav>


    </aside>
  
 
      </header>

      
<article class="markdown"><h1 id="propositional-logic">Propositional Logic</h1>
<p>We have seen in the <a href="http://pantelis.github.io/cs-gy-6613-spring-2020/docs/lectures/planning/search/">route planning</a> module that for some problems agents do not need to possess significant representational abilities - its enough to represent the environment states as <em>atomic</em>.</p>
<p>We also have seen in an earlier chapter where we introduced a <em>dynamical system</em> governing the state evolution of the environment that a state is composed of variables and such <em>factored representations</em> are key in allowing <em>reasoning</em> at the <em>belief</em> space that are efficiently computed using recursive state estimators. We called this subsystem <em>probabilistic reasoning</em> subsystem and we positioned it immediately after the reflexive perception for a good reason. It is processing a very high &lsquo;bandwidth&rsquo; state information that is noisy and needs to be filtered by - you guessed it - Bayesian filters to make it very useful for the subsequent upstream services of the AI system.</p>
<p>In this chapter we will see another powerful representation, <em>internal</em> to the agent, that can help agents to <em>reason</em> by expressing assertions about the world. These assertions are called <em>sentences</em> and are expressed in a <em>knowledge representation language</em> that is used to build a  <strong>Knowledge Base (KB)</strong> - a concept central to AI. The KB starts with prior knowledge about the domain and problem at hand and incrementally is updated with the output of the probabilistic reasoning subsystem.</p>
<p>Lets see a concrete example as described in the figure below,</p>
<p><img src="images/abandoned-backpack.jpg#center" alt="abandoned-backpack">
<em>Imagine that the agent is a security robot at an airport and is moving around an environment it hasnt seen before. The problem it tries to solve is to identify an abandoned backpack / luggage.</em></p>
<p>Despite the simplicity of the problem statement this is a very challenging problem to solve. To begin with the robot must be creating static maps of the environment to be able to navigate it. Closer to the core task, we will need to preprogram the agent with all sorts of deep learning models to be able to even recognize a backpack in its perception system. Unique object ID must be assigned (symbolic segmentation) and a very accurate scene graph must also be generated by its probabilistic reasoning system. It does not stop there, the agent must be able to distinguish a situation  where the backpack that was left behind by its carrier to a companion traveler to e.g. visit the restroom from the situation where the backpack was left behind maliciously. Relational information must therefore be generated to associate objects (e.g. carriers and pieces of luggage) and such information must be stored in the KB but perhaps more importantly the agent must be able to <strong>reason</strong> using the stored information in the KB.</p>
<p>For example, for the sentence $\beta$ that declares that the backpack was separated from the owner, we need to <em>entail</em> a sentence $\alpha$ (and we denote it as $\alpha \models \beta$) that the backpack was handed over to $\mathtt{nobody}$ and therefore justify an action to sound the security alarm. Note the direction in notation: $\alpha$ is a stronger assertion that $\beta$.</p>
<h2 id="world-models">World Models</h2>
<p>For each problem like the abandoned luggage above, we can define a number of <em>world models</em> each representing every possible state (configuration) of the environment that the agent may be in. The specific world model $m$ is, in other words, a mathematical abstraction that fixes as TRUE or FALSE each of the sentences it contains and as you understand, depending on the sentences, it may or may not correspond to reality. For example, the sentence</p>
<p>$$c = \text{&ldquo;backpack is hanging from the ceiling&rdquo;}$$</p>
<p>may be part of a model but it does not correspond to reality and chances are that this sentence will not be <em>satisfied</em> in many models that contain it. We denote the set of models that satisfy sentence $\alpha$ as $M(\alpha)$. We also say that $m$ is a model of $\alpha$. Now that we have defined the world model we can go back to the definition of entailment in the earlier example and write:</p>
<p>$$ \alpha \models \beta  \iff M(\alpha) ⊆ M(\beta)$$</p>
<p>The representation language used in the KB sentences must offer two features: clear syntax and clear meaning (semantics). To describe both we will use a very simple world known in the literature as the Wumpus World (a cave) shown below.</p>
<p><img src="images/wumpus-world.png#center" alt="wumpus-world">
<em>Wumpus World. It was inspired by a video game Hunt the Wumpus by Gregory Yob in 1973. The Wumpus world is a cave which has 4/4 rooms connected with passageways. So there are total 16 rooms which are connected with each other. We have a agent who will move in this world. The cave has a room with a beast which is called Wumpus, who eats anyone who enters the room. The Wumpus can be shot by the agent, but the agent has a single arrow. There are pit rooms which are bottomless, and if agent falls in such pits, then he will be stuck there forever. The agent&rsquo;s goal is to find the gold and climb out of the cave without falling into pits or eaten by Wumpus. The agent will get a reward if he comes out with gold, and he will get a penalty if eaten by Wumpus or falls in the pit.</em></p>
<p>The Performance Environment Actuators and Sensors (PEAS) description is summarized in the table.</p>
<table>
<thead>
<tr>
<th><strong>Attribute</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Environment</strong></td>
<td>Locations of gold and wumpus are uniformly random while any cell other than the starting cell can be a pit with probability of 0.2. One instantiation of the environment that is going to be fixed throughout the problem solving exercise is shown in the figure above. The agent always start at [1,1] facing to the right.</td>
</tr>
<tr>
<td><strong>Performance</strong></td>
<td>+1000 points for picking up the gold. This is the goal of the agent.</td>
</tr>
<tr>
<td></td>
<td>−1000 points for dying. Entering a square containing a pit or a live Wumpus monster.</td>
</tr>
<tr>
<td></td>
<td>−1 point for each action taken so that the agent should avoid performing unnecessary actions.</td>
</tr>
<tr>
<td></td>
<td>−10 points for using the arrow trying to kill the Wumpus.</td>
</tr>
<tr>
<td><strong>Actions</strong></td>
<td><em>Turn 90◦</em> left or right</td>
</tr>
<tr>
<td></td>
<td><em>Forward</em> (walk one square) in the current direction</td>
</tr>
<tr>
<td></td>
<td><em>Grab</em> an object in this square</td>
</tr>
<tr>
<td></td>
<td><em>Shoot</em> the single arrow in the current direction, which flies in a straight line until it hits a wall or the Wumpus</td>
</tr>
<tr>
<td></td>
<td><em>Climb</em> out of the cave - this is possible only in the starting location [1,1]</td>
</tr>
<tr>
<td><strong>Sensors</strong></td>
<td><em>Stench</em> when the Wumpus is in an adjacent square — directly, not diagonally</td>
</tr>
<tr>
<td></td>
<td><em>Breeze</em> when an adjacent square has a pit</td>
</tr>
<tr>
<td></td>
<td><em>Glitter</em> when the agent perceives the glitter of the gold in the current square</td>
</tr>
<tr>
<td></td>
<td><em>Bump</em> when the agent walks into an enclosing wall (and then the action had no effect)</td>
</tr>
<tr>
<td></td>
<td><em>Scream</em> when the arrow hits the Wumpus, killing it.</td>
</tr>
</tbody>
</table>
<p>To use the definitions we saw in the <a href="http://pantelis.github.io/cs-gy-6613-spring-2020/docs/lectures/ai-intro/agents/">introductory chapter</a> the environment is:</p>
<ul>
<li><em>Static</em>: It is static as Wumpus and Pits are not moving.</li>
<li><em>Discrete</em>: The environment is discrete.</li>
<li><em>Partially observable</em>: The Wumpus world is partially observable because the agent can only perceive the close environment such as an adjacent room.</li>
<li><em>Sequential</em>: The order is important, so it is sequential.</li>
</ul>
<p>But why this problem requires <em>reasoning</em>? Simply put, the agent needs to infer the state of adjacent cells from its perception subsystem in the current cell <strong>and</strong> the knowledge of the rule of the wumpus world. These inferences will help the agent to <em>only</em> move to an adjacent cell when it has determined that the cell is OK for it move into.</p>
<p><img src="images/wumpus-seq01.png#center" alt="wumpus-seq01">
<em>Agent A moving in the environment infering the contents of adjacent cells. (a) Initial environment after percept [Stench, Breeze, Glitter, Bump, Scream]=[None, None, None, None, None]. (b) After one move with percept [Stench, Breeze, Glitter, Bump, Scream]=[None, Breeze, None, None, None].</em></p>
<table>
<thead>
<tr>
<th>Environment State</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>(a)</td>
<td>Agent A starts at [1, 1] facing right. The background knowledge β assures agent A that he is at [1, 1] and that it is OK = certainly not deadly.</td>
</tr>
<tr>
<td></td>
<td>Agent A gets the percept [Stench, Breeze, Glitter, Bump, Scream]=[None, None, None, None, None].</td>
</tr>
<tr>
<td></td>
<td>Agent A infers from this percept and β that its both neighboring squares [1, 2] and [2, 1] are also OK: “If there was a Pit (Wumpus), then here would be Breeze (Smell) — but isn’t, so. . . ”.  The KB enables agent A to discover certainties about parts of its environment — even without visiting those parts.</td>
</tr>
<tr>
<td>(b)</td>
<td>Agent A is cautious, and will only move to OK squares. Agent A walks into [2, 1], because it is OK, and in the direction where agent A is facing, so it is cheaper than the other choice [1, 2]. Agent A also marks [1, 1] Visited.</td>
</tr>
<tr>
<td></td>
<td>Agent A perceives [Stench, Breeze, Glitter, Bump, Scream]=[None, Breeze, None, None, None]. Agent A infers: “At least one of the adjacent squares [1, 1], [2, 2] and [3, 1] must contain a Pit. There is no Pit in [1, 1] by my background knowledge β. Hence [2, 2] or [3, 1] or both must contain a Pit.” Hence agent A cannot be certain of either [2, 2] or [3, 1], so [2, 1] is a dead-end for a cautious agent like A.</td>
</tr>
</tbody>
</table>
<p><img src="images/wumpus-seq35.png#center" alt="wumpus-seq35">
<em>Agent moving in the environment infering the contents of adjacent cells.  (a) After the 3rd move and percept [Stench, Breeze, Glitter, Bump, Scream]=[Stench, None, None, None, None]. (b) After the 5th move with percept [Stench, Breeze, Glitter, Bump, Scream]=[Stench, Breeze, Glitter, None, None].</em></p>
<table>
<thead>
<tr>
<th>Environment State</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>(a)</td>
<td>Agent A has turned back from the dead end [2, 1] and walked to examine the other OK choice [1, 2] instead.</td>
</tr>
<tr>
<td></td>
<td>Agent A perceives [Stench, Breeze, Glitter, Bump, Scream]=[Stench, None, None, None, None].</td>
</tr>
<tr>
<td></td>
<td>Agent A infers using also earlier percepts: “The Wumpus is in an adjacent square. It is not in [1, 1]. It is not in [2, 2] either, because then I would have sensed a Stench in [2, 1]. Hence it is in [1, 3].”</td>
</tr>
<tr>
<td></td>
<td>Agent A infers using also earlier inferences: “There is no Breeze here, so there is no Pit in any adjacent square. In particular, there is no Pit in [2, 2] after all. Hence there is a Pit in [3, 1].”</td>
</tr>
<tr>
<td></td>
<td>Agent A finally infers: “[2, 2] is OK after all — now it is certain that it has neither a Pit nor the Wumpus.”</td>
</tr>
<tr>
<td>(b)</td>
<td>Agent A walks to the only unvisited OK choice [2, 2]. There is no Breeze here, and since the square of the Wumpus is now known too, [2, 3] and [3, 2] are OK too.</td>
</tr>
<tr>
<td></td>
<td>Agent A walks into [2, 3] and senses the Glitter there, so it grabs the gold and succeeds.</td>
</tr>
</tbody>
</table>
<h2 id="model-checking-inference">Model-Checking Inference</h2>
<p>The wumpus world despite its triviality, contains some deeper abstractions that are worth summarizing.</p>
<ol>
<li>
<p>Logical inference can be done via an internal representation that are sentences - their syntax and semantics we will examined next.</p>
</li>
<li>
<p>Sentences may be expressed in <em>natural</em> language. Together with the perception and probabilistic reasoning subsystems that can generate symbols associated with a task, the natural language can be <em>grounded</em> and inferences can be drawn in a &lsquo;soft&rsquo; or probabilistic way at the symbolic level.</p>
</li>
</ol>
<p>The reasoning algorithm regarding the possible state of the environment in surrounding cells that the agent performed informally above, is called <em>model checking</em> because it enumerates <em>all possible</em> models to check that a sentence $a$ is supported by the KB i.e. $M(KB) ⊆ M(\alpha)$.</p>
<p><img src="images/wumpus-nonentailment.png#center" alt="wumpus-noentailment">
<em>Possible Models in the presence of pits in cells [1,2],[2,2] and [3,1]. There are $2^3=8$ possible models. The KB when the percepts indicate nothing in cell [1,1] and a breeze in [2,1] is shown as a solid line. With dotted line we show all models of $a_1=\text{&ldquo;not have a pit in [1,2]&quot;}$ sentence</em>.</p>
<p><img src="images/wumpus-entailment.png#center" alt="wumpus-entailment">
<em>Same situation as the figure above but we indicate with dot circle a different sentence $a_2$. What is this sentence?</em></p>
<h2 id="propositional-logic-syntax">Propositional Logic Syntax</h2>
<p>The syntax defines the allowable sentences that can be complex. Each <em>atomic</em> sentence consists of a single (propositional) symbol and the fixed symbols TRUE &amp; FALSE. In BNF the atomic sentences or formulas are also called terminal elements. Complex sentences can be constructed from sentences using logical <em>operators</em> (connectives that connect two or more sentences). In evaluating complex sentences the operator precedence shown in the figure below must be followed.</p>
<p><img src="images/BNF-grammar-prop-logic.png#center" alt="BNF-grammar-prop-logic">
<em>BNF grammar of propositional logic</em></p>
<p>Out of all the operators, two are worthy of further explanation.</p>
<ol>
<li>imply (⇒) operator: the left hand side is the <em>premise</em> and the  right hand side is the implication or conclusion or consequent. This is an operator of key importance known as <strong>rule</strong>. Its an if-then statement.</li>
<li>if and only if (⇔) operator: its expressing an equivalence (≡) or a biconditional.</li>
</ol>
<h2 id="propositional-logic-semantics">Propositional Logic Semantics</h2>
<p>The semantics for propositional logic specify how to compute the value of <em>any</em> sentence given a model. To do so we use the following truth table.</p>
<p><img src="images/truth-table.png#center" alt="truth-table">
<em>Truth tables for three primary and five derived logical operators. Note the presence of the XOR connective.</em></p>
<p>Given a world model in the KB</p>
<p>$$m_1 = \left[ P_{1,2}=FALSE, P_{2,2}=FALSE, P_{3,1}=TRUE \right]$$</p>
<p>a sentence can be assigned a truth value (FALSE/TRUE) using the semantics above. For example the sentence,</p>
<p>$$\neg P_{1,2} \land (P_{2,2} \lor P_{3,1}) = TRUE $$</p>
<h2 id="inference-example">Inference Example</h2>
<p>Using the operators and their semantics we can now construct an KB as an example for the wumpus world. We will use the following symbols to describe atomic and complex sentences in this world.</p>
<table>
<thead>
<tr>
<th>Symbols</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>$P_{x,y}$</td>
<td>Pit in cel [x,y]</td>
</tr>
<tr>
<td>$W_{x,y}$</td>
<td>Wumpus (dead or alive) in cel [x,y]</td>
</tr>
<tr>
<td>$B_{x,y}$</td>
<td>Perception of a breeze while in cel [x,y]</td>
</tr>
<tr>
<td>$S_{x,y}$</td>
<td>Perception of a stench while in cel [x,y]</td>
</tr>
</tbody>
</table>
<p>Using these symbols we can convert the natural language assertions into logical sentences and populate the KB. The sentences $R_1$ and $R_2/R_3$ are general rules of the wumpus world. $R_4$ and $R_5$ are specific to the specific world instance and moves of the agent.</p>
<table>
<thead>
<tr>
<th>Sentence</th>
<th>Description</th>
<th>KB</th>
</tr>
</thead>
<tbody>
<tr>
<td>$R_1$</td>
<td>There is no pit in cel [1,1]</td>
<td>$\neg P_{1,1}$</td>
</tr>
<tr>
<td>$R_2$</td>
<td>The cell [1,1] is breezy if and only if there is a pit in the neighboring cell.</td>
<td>$B_{1,1} ⇔ (P_{1,2} \lor P_{2,1})$</td>
</tr>
<tr>
<td>$R_3$</td>
<td>The cell [2,1] is breezy if and only if there is a pit in the neighboring cell.</td>
<td>$B_{2,1} ⇔ (P_{1,1} \lor P_{2,2} \lor P_{3,1})$</td>
</tr>
<tr>
<td>$R_4$</td>
<td>Agent while in cell [1,1] perceives [Stench, Breeze, Glitter, Bump, Scream]=[None, None, None, None, None]</td>
<td>$\neg B_{1,1}$</td>
</tr>
<tr>
<td>$R_5$</td>
<td>Agent while in cell [2,1] perceives [Stench, Breeze, Glitter, Bump, Scream]=[None, Breeze, None, None, None]</td>
<td>$B_{2,1}$</td>
</tr>
</tbody>
</table>
<p>As the agent moves, it uses the KB to decide whether a sentence is entailed by the the KB or not. For example can we infer that there is no pit at cell [1,2] ? The sentence of interest is $ \alpha = \neg P_{1,2}$ and we need to prove that:</p>
<p>$$ KB \models \alpha $$</p>
<p>To answer such question we will use the model checking algorithm outlined in this chapter: enumerate all models and check that $\alpha$ is true for in every model where the KB is true. We construct the truth table that involves the symbols and sentences present in the KB:</p>
<p><img src="images/truth-table-kb.png#center" alt="truth-table-kb"></p>
<p>As described in the figure caption, 3 models out of the $2^7=128$ models make the KB true and in these rows the $P_{1,2}$ is false.</p>
<p>Although the model checking approach was instructive, there is an issue with its complexity. Notice that if there are $n$ symbols in the KB there will be $2^n$ models, the time complexity is $O(2^n)$.</p>
<p>The symbolic representation together with the explosive increase in the number of sentences in the KB as time goes by, cant scale. Another approach to do entailment, potentially more efficient, is  <em>theorem proving</em> where we are applying <em>inference rules</em> directly to the sentences of the KB to construct a proof of the desired sentence/query. Even better, we can invest in new representations as described in the <a href="http://pantelis.github.io/cs-gy-6613-spring-2020/docs/lectures/planning/classical-planning/">PDDL</a> chapter to develop planning approaches that combine search and logic and do not suffer necessarily from the combinatorial explosion problem.</p>
<blockquote class="book-hint info">
  If you need to review the BNF expressed grammar for propositional logic (as shown in the syntax above) review <a href="https://www.youtube.com/watch?v=MMxMeX5emUA">part 1</a> and <a href="https://www.youtube.com/watch?v=DiOxbYTLXX8">part 2</a> video tutorials.
</blockquote>

</article>
 

      <footer class="book-footer">
        
  <div class="flex justify-between">



  <div>
    
    <a class="flex align-center" href="https://github.com/pantelis/cs-gy-6613-spring-2020/commit/53e0b07c3cde366d433cf2beb55611e24263c974" title='Last modified by MONOGIOUDIS Pantelis | Apr 14, 2020' target="_blank" rel="noopener">
      <img src="/cs-gy-6613-spring-2020/svg/calendar.svg" class="book-icon" alt="Calendar" />
      <span>Apr 14, 2020</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/pantelis/cs-gy-6613-spring-2020/edit/master/cs-gy-6613-spring-2020/content/docs/lectures/planning/propositional-logic/_index.md" target="_blank" rel="noopener">
      <img src="/cs-gy-6613-spring-2020/svg/edit.svg" class="book-icon" alt="Edit" />
      <span>Edit this page</span>
    </a>
  </div>

</div>

 
        
  
 
      </footer>
      
    </div>

    
    <aside class="book-toc">
      
  <nav id="TableOfContents">
  <ul>
    <li><a href="#propositional-logic">Propositional Logic</a>
      <ul>
        <li><a href="#world-models">World Models</a></li>
        <li><a href="#model-checking-inference">Model-Checking Inference</a></li>
        <li><a href="#propositional-logic-syntax">Propositional Logic Syntax</a></li>
        <li><a href="#propositional-logic-semantics">Propositional Logic Semantics</a></li>
        <li><a href="#inference-example">Inference Example</a></li>
      </ul>
    </li>
  </ul>
</nav>

 
    </aside>
    
  </main>

  <!DOCTYPE html> 

<link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css"
  integrity="sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG"
  crossorigin="anonymous">

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js"
  integrity="sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1"
  crossorigin="anonymous"></script>

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
  crossorigin="anonymous" onload="renderMathInElement(document.body);">
</script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
          {left: "$$", right: "$$", display: true},
          {left: "$", right: "$", display: false}
      ],
      macros: {
        
        "\\pdata": "p_{data}",
        
        "\\ptrain": "\\hat{p}_{data}",
        "\\Ptrain": "\\hat{P}_{data}",
        
        "\\pmodel": "p_{model}",
        "\\Pmodel": "P_{model}",
        "\\ptildemodel": "\tilde p_{model}",
        
        "\\pencode": "p_{encoder}",
        "\\pdecode": "p_{decoder}",
        "\\precons": "p_{reconstruct}"
      }
    });
  });
</script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"
          integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous">
</script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>

<script>
  pseudocode.renderElement(document.getElementById("forward-search"));
</script>


</html>


</body>

</html>












