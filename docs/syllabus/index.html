<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Syllabus"><meta property="og:title" content="Syllabus" />
<meta property="og:description" content="Syllabus The course schedule below highlights our journey to understand the multiple subsystems and how they can be connected together to create compelling but, currently, domain specific forms of intelligence.
Books Artificial Intelligence: A Modern Approach, by Stuart Russell, 3rd edition, 2010 and also here.
The publisher is about to release the 4th edition (2020) of this classic. We will be monitoring availability in bookstores but it does not seem likely this edition to appear on time for the Spring 2020 class." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://pantelis.github.io/cs-gy-6613-spring-2020/docs/syllabus/" />
<meta property="article:modified_time" content="2020-02-10T13:16:48-05:00" />
<title>Syllabus | CS-GY-6613 Spring 2020</title>
<link rel="icon" href="/cs-gy-6613-spring-2020/favicon.png" type="image/x-icon">


<link rel="stylesheet" href="/cs-gy-6613-spring-2020/book.min.ccf2e3f83640a9c2266488b947be5b9ddbdea671b0de107d1d379f1d6f6d0408.css" integrity="sha256-zPLj&#43;DZAqcImZIi5R75bndvepnGw3hB9HTefHW9tBAg=">


<script defer src="/cs-gy-6613-spring-2020/en.search.min.967a436ce60aeb9d7b009a01a96b0bcc59c8fbe1dd8d8ed91387a538777876e1.js" integrity="sha256-lnpDbOYK6517AJoBqWsLzFnI&#43;&#43;HdjY7ZE4elOHd4duE="></script>

<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body>
  <input type="checkbox" class="hidden" id="menu-control" />
  <main class="container flex">
    <aside class="book-menu">
      
  <nav>
<h2 class="book-brand">
  <a href="/cs-gy-6613-spring-2020"><img src="/cs-gy-6613-spring-2020/tandon_long_black.png" alt="Logo" /><span>CS-GY-6613 Spring 2020</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>





  

  
  





 
  
    




  
  <ul>
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/syllabus/"  class="active">
      Syllabus
  </a>

</li>
      
    
      
        

  <li >
    
      <span>Week 1 - Introduction to AI</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ai-intro/course-introduction/" >
      Course Introduction
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ai-intro/systems-approach/" >
      A systems approach to AI
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ai-intro/ai-pipelines/" >
      The Way of Working in AI
  </a>


    

    




  
  <ul>
    
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ai-intro/agents/" >
      Intelligent Agents and Representations
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/learning-problem/" >
      Week 2a - The Learning Problem
  </a>


    

    




  
  <ul>
    
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Week 2b - Regression</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/regression/linear-regression/" >
      Linear Regression
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/regression/ML-Bayesian-estimation/" >
      Bayesian Linear Regression
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/" >
      Week 2c - Linear Classification
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/knn/" >
      k-Nearest Neighbors (kNN) Classification
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/perceptron/" >
      The Perceptron
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/logistic-regression/" >
      Logistic Regression
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/kernels/" >
      Kernels and the Kernel Trick
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/clustering/" >
      K-means Clustering
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/svm/" >
      Support Vector Machines
  </a>


    

    




  
  <ul>
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/svm/face-recognition/" >
      Face Recognition - SVM Case Study
  </a>

</li>
      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/svm/mnist/" >
      MNIST Classification - SVM Case Study
  </a>

</li>
      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/svm/iris/" >
      Iris Classification - SVM Case Study
  </a>

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/decision-trees/" >
      Decision Trees
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/classification/random-forests/" >
      Random Forests
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/dnn/" >
      Week 3 - Deep Neural Networks
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/dnn/backprop-intro/" >
      Introduction to Backpropagation
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/dnn/backprop-dnn/" >
      Backpropagation in Deep Neural Networks
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/dnn/fashion-mnist-case-study/" >
      Fashion MNIST Case Study
  </a>

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Week 4a - Convolutional Neural Networks</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Introduction to Convolutional Neural Networks</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Attention Mechanisms in CNNs</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/cnn/cnn-arch/" >
      CNN Architectures
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Week 4b - Sequences and Recurrent Neural Networks (RNN)</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Week 5 - Scene Understanding</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Week 5a - Object Detection</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Week 5b - Semantic Segmentation</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/projects/" >
      Projects
  </a>


    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/projects/imu-classification/" >
      Project 1 - Surface Type Classification
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/projects/continuous-learning/" >
      Project 2 - Continual Learning for Robotic Perception
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/projects/env/" >
      Your Programming Environment
  </a>

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Background - Math for ML</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-math/linear-algebra/" >
      Linear Algebra for Machine Learning
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-math/optimization/" >
      Optimization and Stochastic Gradient Descent
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-math/probability/" >
      Probability and Information Theory Basics
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-math/netflix/" >
      The Netflix Prize and Singular Value Decomposition
  </a>


    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/" >
      Background - ML Frameworks
  </a>


    

    




  
  <ul>
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/numpy-pandas/" >
      Numerical Python (Numpy/Scipy and Pandas) Tutorials
  </a>

</li>
      
    
      
        <li>

  <a href="/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/tensorflow-introduction/" >
      Introduction to Tensorflow
  </a>

</li>
      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>A* Search</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Constraint Satisfaction Programming</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Generative Modeling and Continuous Variational Auto Encoders (VAE)</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Introduction to Probabilistic Reasoning</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>Natural Language Processing</span>
    

    




  
  <ul>
    
      
        

  <li >
    
      <span>Creating Reasonable Embeddings</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  </li>


      
    
      
        

  <li >
    
      <span>The Agent - Environment Interface</span>
    

    




  
  <ul>
    
  </ul>
  



  </li>


      
    
  </ul>
  



  











</nav>




  <script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script>


 
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/cs-gy-6613-spring-2020/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Syllabus</strong>

  <label for="toc-control">
    <img src="/cs-gy-6613-spring-2020/svg/toc.svg" class="book-icon" alt="Table of Contents" />
  </label>
</div>


  
    <input type="checkbox" class="hidden" id="toc-control" />
    <aside class="hidden clearfix">
      
  <nav id="TableOfContents">
  <ul>
    <li><a href="#syllabus">Syllabus</a>
      <ul>
        <li><a href="#books">Books</a></li>
        <li><a href="#schedule">Schedule</a>
          <ul>
            <li><a href="#part-i--perception-and-machine-learning">Part I:  Perception and Machine Learning</a></li>
            <li><a href="#part-ii-reasoning-and-planning">Part II: Reasoning and Planning</a></li>
            <li><a href="#part-iii-deep-reinforcement-learning">Part III: Deep Reinforcement Learning</a></li>
            <li><a href="#part-iv-knowledge-bases-and-communication">Part IV: Knowledge Bases and Communication</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


    </aside>
  
 
      </header>

      
<article class="markdown"><h1 id="syllabus">Syllabus</h1>
<p>The course schedule below highlights our journey to understand the multiple subsystems and how they can be connected together to create compelling but, currently, domain specific forms of intelligence.</p>
<h2 id="books">Books</h2>
<p><a href="https://www.amazon.com/Artificial-Intelligence-Approach-Stuart-Russell/dp/9332543518/ref=sr_1_2?crid=17NGBV1XXV150&amp;keywords=ai+a+modern+approach&amp;qid=1576432665&amp;sprefix=ai+the+modern+appr%2Caps%2C158&amp;sr=8-2">Artificial Intelligence: A Modern Approach, by Stuart Russell, 3rd edition, 2010</a> and also <a href="http://aima.cs.berkeley.edu/">here.</a></p>
<p>The publisher is about to release the <a href="https://www.amazon.com/Artificial-Intelligence-A-Modern-Approach/dp/0134610997/ref=sr_1_3?crid=17NGBV1XXV150&amp;keywords=ai+a+modern+approach&amp;qid=1576432686&amp;sprefix=ai+the+modern+appr%2Caps%2C158&amp;sr=8-3">4th edition (2020) of this classic</a>. We will be monitoring availability in bookstores but it does not seem likely this edition to appear on time for the Spring 2020 class.</p>
<p>Other recommended texts are: (a) DRL: &ldquo;Foundations of Deep Reinforcement Learning&rdquo;, by Graesser &amp; Keng, 2020. (b) GERON: &ldquo;Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow&rdquo;, 2nd Edition, by Geron, 2019. (c) DL: <a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a> (free)</p>
<h2 id="schedule">Schedule</h2>
<p>The schedule is based on <a href="https://www.nyu.edu/registrar/calendars/university-academic-calendar.html">Academic Calendar Spring 2020</a>:</p>
<h3 id="part-i--perception-and-machine-learning">Part I:  Perception and Machine Learning</h3>
<ol>
<li>
<p><strong>Week 1 (1/27/2020)</strong> We start with an introduction to AI and present a systems approach towards it. We develop a map that will guide us through the rest of the course as we deep dive into each component embedded into <em>AI agents</em>. Reading: AIMA Chapters 1 &amp; 2.</p>
</li>
<li>
<p><strong>Week 2 (2/3/2020)</strong>  The perception subsystem is the first stage of many AI systems including our brain. Its function is to process and fuse multimodal sensory inputs. Perception is implemented via a number of reflexive agents that map directly perceived state to an primitive action such as regressing on the frame coordinates of an object in the scene. We present <em>the supervised learning problem</em> both for classification and regression, starting with classical ML algorithms. Reading: AIMA Chapter 18.</p>
</li>
<li>
<p><strong>Week 3 (2/10/2020)</strong>  We expand into <em>Deep neural networks</em>. DNNs are developed bottom up from the Perceptron algorithm. MLPs learn via optimization approaches such as Stochastic Gradient Descent.  We deep-dive into back-propagation - a fundamental algorithm that efficiently trains DNNs. Reading: DL Chapter 6</p>
</li>
<li>
<p><strong>Week 4: (2/[17]/2020) Since this is President&rsquo;s Day, we need to decide which day we can have the lecture.</strong> We dive into the most dominant DNN architecture today -  <em>Convolutional Neural Networks (CNNs) and Recursive Neural Networks (RNNs)</em>. Reading: DL Chapter 9 &amp; 10.</p>
</li>
<li>
<p><strong>Week 5: (2/24/2020)</strong> When agents move in the environment they need to abilities such as <em>scene understanding</em>.  We will go through few key perception building blocks such as Object Detection, Semantic and Instance Segmentation. Some of these building blocks (autoencoders) are instructive examples of representations learning that will be shown to be an essential tool in the construction of environment state representations. Reading: Various papers</p>
</li>
</ol>
<h3 id="part-ii-reasoning-and-planning">Part II: Reasoning and Planning</h3>
<ol start="6">
<li>
<p><strong>Week 7: (3/2/2020)</strong>  In this lecture we introduce probabilistic models that process the outputs of perception (measurement / sensor model) and the state transitions and understand how the agent will track / update its belief state over time. This is a achieved with probabilistic recursive state estimation algorithms and dynamic bayesian networks. Reading: AIMA Chapters 14 &amp; 15.</p>
</li>
<li>
<p><strong>Week 6: (3/9/2020)</strong> After the last lecture, the agent has a clear view of the environment state such as what and where the objects that surround it are, its able to track them as they potentially move. It needs to plan the best sequence of actions to reach its goal state and the approach we take here is that of <em>problem solving</em>. In fact planning and problem solving are inherently connected as concepts. If the goal state is feasible then the problem to solve  becomes that of  <em>search</em>. For instructive purposes we start from simple environmental conditions that are fully observed, known and deterministic. This is where the A* algorithm comes in. We then relax some of the assumptions and treat environments that are deterministic but the agent takes stochastic actions or when both the environment and agent actions are stochastic. Reading: AIMA Chapters 3 &amp; 4.</p>
</li>
<li>
<p><strong>Week 8: (3/16/2020)</strong>  Enjoy your Spring Break.</p>
</li>
<li>
<p><strong>Week 9: (3/23/2020) - This is your Midterm Test (2h)</strong></p>
</li>
<li>
<p><strong>Week 10: (3/30/2020)</strong>  We continue on our path (literally :) ) to investigate what happens when we do not just care about reaching our goal state, but when we, in addition, need to do so with optimality. Optimal planning under uncertainty is perhaps the cornerstone application today in robotics and other fields. Readings: AIMA Chapters 10 &amp; 11 and selected papers.</p>
</li>
</ol>
<h3 id="part-iii-deep-reinforcement-learning">Part III: Deep Reinforcement Learning</h3>
<ol start="11">
<li>
<p><strong>Week 11: (4/6/2020)</strong> We now make a considerable extension to our assumptions: the utility of the agent now depends on a sequence of decisions and, further, the stochastic environment offers a feedback signal to the agent called <em>reward</em>. We review how the agent&rsquo;s policy, the sequence of actions, can be calculated when it fully observes its current state (MDP) and also when it can only partially do so (POMDP). The algorithms that learn optimal policies in such settings are known as Reinforcement Learning (RL). Today they are enhanced with the Deep Neural Networks that we met in Part I, to significantly improve the expected reward since DNNs are excellent approximators to the various functions embedded in such problems. We conclude with the basic taxonomy of the algorithm space for DRL Problems. In this course we are focusing on model free methods that have general applicability.  Readings: AIMA Chapter 16 &amp; 17, DRL Chapter 1. This lectured will be delivered in person by Gurudutt Hossangadi as I will be out of town.</p>
</li>
<li>
<p><strong>Week 12: (4/13/2020)</strong>  In this lecture we start on the exploration of the various algorithms that do not depend on learning any model of the environment dynamics. The first algorithm is the policy-based algorithm called REINFORCE and its extensions especially the Advantage Actor Critic (A2C).   DRL Chapter 2, 6 and 7.</p>
</li>
<li>
<p><strong>Week 13: (4/20/2020)</strong>  Staying in the setting of model-free algorithms we will work with the so-called value-based methods and the State Action Reward State Action (SARSA) algorithms. This is the ancestor of algorithms such as DQN, DDQN with Prioritized Experience Replay (PER) that will also be covered. Readings: DRL Chapter 3, 4 and 5.</p>
</li>
</ol>
<h3 id="part-iv-knowledge-bases-and-communication">Part IV: Knowledge Bases and Communication</h3>
<ol start="14">
<li>
<p><strong>Week 14: (4/27/2019)</strong>  Every intelligent agent needs to know how the world works for each task it encounters. These facts are stored in its Knowledge Base also known as Knowledge Graph. In addition as the agent affects the environment it must be able to create the right representations using its perception systems and update the knowledge base with dynamic content. Finally it needs to draw conclusions - aka infer new facts from existing ones - that will help the task at hand.  Readings: AIMA Chapter 12 and selected papers.</p>
</li>
<li>
<p><strong>Week 15: (5/05/2020)</strong>  We are all familiar that natural language is the prime means of communication between humans to collaboratively complete successfully tasks or simply share our knowledge bases. How can we achieve the same objectives when we enable communicate with intelligent agents. Is natural language the universal language that together with imitation is the missing link in our ability to (re)task robots from intelligent assistants to cognitive collaborative robots in our factories of the future? Readings: AIMA Chapter 23 and selected papers.</p>
</li>
<li>
<p><strong>Week 16: (5/11/2020)</strong> In this last lecture, we review the main points of what we learned and emphasize what kind of questions you are expected to answer in the final exam. <strong>Final projects are due 5/10/2020 11:59pm.</strong></p>
</li>
<li>
<p><strong>Week 17: (5/18/2020)</strong>  Good luck with your final test.</p>
</li>
</ol>
</article>
 

      <footer class="book-footer">
        
  <div class="flex justify-between">



  <div>
    
    <a class="flex align-center" href="https://github.com/pantelis/cs-gy-6613-spring-2020/commit/043f332700cbc67e888d9e6b8f668ed013f5d150" title='Last modified by MONOGIOUDIS Pantelis | Feb 10, 2020' target="_blank" rel="noopener">
      <img src="/cs-gy-6613-spring-2020/svg/calendar.svg" class="book-icon" alt="Calendar" />
      <span>Feb 10, 2020</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/pantelis/cs-gy-6613-spring-2020/edit/master/cs-gy-6613-spring-2020/content/docs/syllabus/index.md" target="_blank" rel="noopener">
      <img src="/cs-gy-6613-spring-2020/svg/edit.svg" class="book-icon" alt="Edit" />
      <span>Edit this page</span>
    </a>
  </div>

</div>

 
        
  
 
      </footer>
      
    </div>

    
    <aside class="book-toc">
      
  <nav id="TableOfContents">
  <ul>
    <li><a href="#syllabus">Syllabus</a>
      <ul>
        <li><a href="#books">Books</a></li>
        <li><a href="#schedule">Schedule</a>
          <ul>
            <li><a href="#part-i--perception-and-machine-learning">Part I:  Perception and Machine Learning</a></li>
            <li><a href="#part-ii-reasoning-and-planning">Part II: Reasoning and Planning</a></li>
            <li><a href="#part-iii-deep-reinforcement-learning">Part III: Deep Reinforcement Learning</a></li>
            <li><a href="#part-iv-knowledge-bases-and-communication">Part IV: Knowledge Bases and Communication</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>

 
    </aside>
    
  </main>

  <!DOCTYPE html> 

<link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css"
  integrity="sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG"
  crossorigin="anonymous">

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js"
  integrity="sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1"
  crossorigin="anonymous"></script>

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
  crossorigin="anonymous" onload="renderMathInElement(document.body);">
</script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
          {left: "$$", right: "$$", display: true},
          {left: "$", right: "$", display: false}
      ]
    });
  });
</script>


</html>

</body>

</html>












