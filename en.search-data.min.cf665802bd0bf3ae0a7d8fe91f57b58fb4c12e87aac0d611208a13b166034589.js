'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/cs-gy-6613-spring-2020/docs/lectures/ai-intro/course-introduction/','title':"Course Introduction",'content':" AI Evolution according to DARPA If engineering difficulty has a pinnacle today this must be in AI domains that combines ML, optimal control and planning. autonomous cars and humanoids from Boston Dynamics fit the bill.\nInitially there were rules.\n In the 1980s knowledge-base systems that hard-coded knowledge about the world in formal languages.  IF this happens, THEN do that.  They failed to get significant traction as the number of rules that are needed to model the real world exploded. However, they are still in use today in vertical modeling domains e.g. fault management. For example Rule Based Engines are used today in many complex systems that manage mission critical infrastructures e.g. ONAP.  The introduction of advanced AI methods few years ago, created a situation we can explain with the following analogy.\nA nautical analogy on where we are today on AI for mission critical systems. Can you notice anything strange with this ship (Cumberland Basin, photo taken April 1844)?\nTo put order into the many approaches and methods for delivering AI in our lives, DARPA classified AI development in terms of \u0026ldquo;waves\u0026rdquo;.\n         Wave I: GOFAI Wave II: Connectionism Wave III: AGI   In the 1980s Rule Based Engines started to be applied manifesting the first wave of AI introduction. In this example you see a system that performs highway trajectory planning. A combination of cleverly designed rules does work and offers real time performance but cannot generalize and therefore have acceptable performance in other environments.\nWave II srarted soon after 2010 - we started to apply a different philosophy in solving intelligent tasks such as object classification. The philosophy of connectionism and the so called deep neural network architectures, dominate today relative simple (and mostly self-contained) tasks.\nWave III is at present an active research area driven primarily from our inability to implement with just deep neural networks things like long-term goal planning, causality, extract meaning from text like humans do, explain the decisions of neural networks, transfer the learnings from one task to another, even similar, task. Artificial General Intelligence is the term usually associated with such capabilities.\nFurther, we will see a fusion of disciplines such as physical modeling and simulation with representation learning to help deep neural networks learn using data generated by domain specific simulation engines.\nReveal the stenosis:Generative augmented physical (Computational Fluid Dynamics) modeling from Computer Tomography Scans\nFor example in the picture above a CFD simulation is used to augment ML algorithms that predict and explain those predictions. I mission critical systems (such as medical diagnostic systems) everything must be explainable.\nConsult the course Syllabus to understand what elements of Wave II AI systems we will cover in this course.\n"});index.add({'id':1,'href':'/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/numpy-pandas/','title':"Numerical Python (Numpy/Scipy and Pandas) Tutorials",'content':" Standard Python Below is a list of recommended courses you can attend to. We will go over briefly basic Python in this lecture. The tutorials below are self contained and can remind you the basics.\n CodeAcademy Data Science Path. Take Python modules 4-10. This course contains Numpy and Panda intro as well.\n Kaggle Python Course\n Google Python Class This is a bit dated as it covers Python 2, but it is still highly regarded as Python 3 and 2 have few differences.\n  Numpy specific We will go Numpy Tutorial from Stanford\u0026rsquo;s CS231n. \u0026gt; Numpy Cheatsheet\nPandas (optional) Pandas may not be needed for the AI course. In any case, this is the effectively \u0026ldquo;official\u0026rdquo; documentation on Pandas: Pandas: powerful Python data analysis toolkit\n"});index.add({'id':2,'href':'/cs-gy-6613-spring-2020/docs/syllabus/','title':"Syllabus",'content':" Syllabus The course schedule below highlights our journey to understand the multiple subsystems and how they can be connected together to create compelling but, currently, domain specific forms of intelligence.\nBooks Artificial Intelligence: A Modern Approach, by Stuart Russell, 3rd edition, 2010 and also here.\nThe publisher is about to release the 4th edition (2020) of this classic. We will be monitoring availability in bookstores but it does not seem likely this edition to appear on time for the Spring 2020 class.\nOther recommended texts are: (a) DRL: \u0026ldquo;Foundations of Deep Reinforcement Learning\u0026rdquo;, by Graesser \u0026amp; Keng, 2020. (b) GERON: \u0026ldquo;Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\u0026rdquo;, 2nd Edition, by Geron, 2019. \u0026copy; DL: https://www.deeplearningbook.org/ (free)\nSchedule The schedule is based on Academic Calendar Spring 2020:\nPart I: Perception and Machine Learning  Week 1 (1/27/2020) We start with an introduction to AI and present a systems approach towards it. We develop a map that will guide us through the rest of the course as we deep dive into each component embedded into AI agents. Reading: AIMA Chapters 1 \u0026amp; 2.\n Week 2 (2/3/2020) The perception subsystem is the first stage of many AI systems including our brain. Its function is to process and fuse multimodal sensory inputs. Perception is implemented via a number of reflexive agents that map directly perceived state to an primitive action such as regressing on the frame coordinates of an object in the scene. We present the supervised learning problem both for classification and regression, starting with classical ML algorithms. Reading: AIMA Chapter 18.\n Week 3 (2/10/2020) We expand into Deep neural networks. DNNs are developed bottom up from the Perceptron algorithm. MLPs learn via optimization approaches such as Stochastic Gradient Descent. We deep-dive into back-propagation - a fundamental algorithm that efficiently trains DNNs. Reading: DL Chapter 6\n Week 4: (2/[17]/2020) Since this is President\u0026rsquo;s Day, we need to decide which day we can have the lecture. We dive into the most dominant DNN architecture today - Convolutional Neural Networks (CNNs) and Recursive Neural Networks (RNNs). Reading: DL Chapter 9 \u0026amp; 10.\n Week 5: (2/24/2020) When agents move in the environment they need to abilities such as scene understanding. We will go through few key perception building blocks such as Object Detection, Semantic and Instance Segmentation. Some of these building blocks (autoencoders) are instructive examples of representations learning that will be shown to be an essential tool in the construction of environment state representations. Reading: Various papers\n  Part II: Reasoning and Planning  Week 7: (3/2/2020) In this lecture we introduce probabilistic models that process the outputs of perception (measurement / sensor model) and the state transitions and understand how the agent will track / update its belief state over time. This is a achieved with probabilistic recursive state estimation algorithms and dynamic bayesian networks. Reading: AIMA Chapters 14 \u0026amp; 15.\n Week 6: (3/9/2020) After the last lecture, the agent has a clear view of the environment state such as what and where the objects that surround it are, its able to track them as they potentially move. It needs to plan the best sequence of actions to reach its goal state and the approach we take here is that of problem solving. In fact planning and problem solving are inherently connected as concepts. If the goal state is feasible then the problem to solve becomes that of search. For instructive purposes we start from simple environmental conditions that are fully observed, known and deterministic. This is where the A* algorithm comes in. We then relax some of the assumptions and treat environments that are deterministic but the agent takes stochastic actions or when both the environment and agent actions are stochastic. Reading: AIMA Chapters 3 \u0026amp; 4.\n Week 8: (3/16/2020) Enjoy your Spring Break.\n Week 9: (3/23/2020) - This is your Midterm Test (2h)\n Week 10: (3/30/2020) We continue on our path (literally :) ) to investigate what happens when we do not just care about reaching our goal state, but when we, in addition, need to do so with optimality. Optimal planning under uncertainty is perhaps the cornerstone application today in robotics and other fields. Readings: AIMA Chapters 10 \u0026amp; 11 and selected papers.\n  Part III: Deep Reinforcement Learning  Week 11: (4/6/2020) We now make a considerable extension to our assumptions: the utility of the agent now depends on a sequence of decisions and, further, the stochastic environment offers a feedback signal to the agent called reward. We review how the agent\u0026rsquo;s policy, the sequence of actions, can be calculated when it fully observes its current state (MDP) and also when it can only partially do so (POMDP). The algorithms that learn optimal policies in such settings are known as Reinforcement Learning (RL). Today they are enhanced with the Deep Neural Networks that we met in Part I, to significantly improve the expected reward since DNNs are excellent approximators to the various functions embedded in such problems. We conclude with the basic taxonomy of the algorithm space for DRL Problems. In this course we are focusing on model free methods that have general applicability. Readings: AIMA Chapter 16 \u0026amp; 17, DRL Chapter 1. This lectured will be delivered in person by Gurudutt Hossangadi as I will be out of town.\n Week 12: (4/13/2020) In this lecture we start on the exploration of the various algorithms that do not depend on learning any model of the environment dynamics. The first algorithm is the policy-based algorithm called REINFORCE and its extensions especially the Advantage Actor Critic (A2C). DRL Chapter 2, 6 and 7.\n Week 13: (4/20/2020) Staying in the setting of model-free algorithms we will work with the so-called value-based methods and the State Action Reward State Action (SARSA) algorithms. This is the ancestor of algorithms such as DQN, DDQN with Prioritized Experience Replay (PER) that will also be covered. Readings: DRL Chapter 3, 4 and 5.\n  Part IV: Knowledge Bases and Communication  Week 14: (4/27/2019) Every intelligent agent needs to know how the world works for each task it encounters. These facts are stored in its Knowledge Base also known as Knowledge Graph. In addition as the agent affects the environment it must be able to create the right representations using its perception systems and update the knowledge base with dynamic content. Finally it needs to draw conclusions - aka infer new facts from existing ones - that will help the task at hand. Readings: AIMA Chapter 12 and selected papers.\n Week 15: (5/05/2020) We are all familiar that natural language is the prime means of communication between humans to collaboratively complete successfully tasks or simply share our knowledge bases. How can we achieve the same objectives when we enable communicate with intelligent agents. Is natural language the universal language that together with imitation is the missing link in our ability to (re)task robots from intelligent assistants to cognitive collaborative robots in our factories of the future? Readings: AIMA Chapter 23 and selected papers.\n Week 16: (5/11/2020) In this last lecture, we review the main points of what we learned and emphasize what kind of questions you are expected to answer in the final exam. Final projects are due 5/10/2020 11:59pm.\n Week 17: (5/18/2020) Good luck with your final test.\n  "});index.add({'id':3,'href':'/cs-gy-6613-spring-2020/docs/lectures/ai-intro/systems-approach/','title':"A systems approach to AI",'content':" The four approaches towards AI The Turing Test Approach A 5-min behavioral intelligence test, where an interrogator chats with the player and at the end it guesses if the conversation is with a human or with a programmed machine. A Turing contest (Loebner Prize) is is held annually since 1991.\nThis course\u0026rsquo;s projects includes the Alexa prize which is not a turing test. The Alexa Prize creates social bots that engage in interesting, human-like conversations, not to make them indistinguishable from a human when compared side-by-side. Social bots may have ready access to much more information than a human.\n       Summary of the Turing Test The Alexa Prize is not a Turing Test   What capabilities we need to have to pass a turing test.\n Natural Language Processing Knowledge Representation Automated Reasoning Machine Learning Computer Vision Robotics  The last two capabilities are not needed for the verbal oriented Turing test but they are needed for what is called the total Turing test. According to this test, the player and the interrogator can communicate physically. For example, there is a hatch where the interrogator can pass objects to the player through. Obviously the player must have perception abilities to understand what object it is (5) and possibly a body that can manipulate the object (6). Embodied AI research is one of the hotter areas of AI today as we will see in the Agents section.\nThe Cognitive Model approach Newell, in his book \u0026ldquo;Unified Theories of Cognition\u0026rdquo;, defines cognition as:\n Memory, learning, skill Perception, motor behavior Problem solving, decision making, routine action Language Motivation, emotion Imagining, dreaming   How do we differentiate a cognitive model from a conceptual or statistical model? “Cognitive science is concerned with understanding the processes that the brain uses to accomplish complex tasks including perceiving, learning, remembering, thinking, predicting, problem solving, decision making, planning, and moving around the environment. The goal of a cognitive model is to scientifically explain one or more of these basic cognitive processes, or explain how these processes interact.”, \u0026ndash;Busemeyer \u0026amp; Diederich (2010)\n These theories of cognitive processes are tested via various cognitive architectures. Its important to realize that much of todays\u0026rsquo; debate about the path ahead in AI maps to the few different architectures. The hybrid architecture (symbolic and connection-oriented) is what is being investigated today by many research institutions.\nThe Syllogism-based approach The translation from Greek of the word syllogism is to support logic.\nThis approach emphasizes how we think the right way and encodes the pattern of logical arguments that can reach correct conclusions from a set of propositions (premises). Problem solving where the problem statement is expressed in a logic notation, matured in the 60s. As we have seen in the course introduction such rule-based systems are still with us and for small and deterministic state spaces can provide a very compact and elegant way to inference.\nLogic-based reasoning is coming back to fashion. One of the most promising areas is their application to interpretability (also known as explainability ) of deep learning based methods for e.g. classification in medical diagnosis. Probabilistic Logic Networks (PLN) are extensions of this approach to address problems with uncertainty.\nThe Rational Agent approach A rational agent acts to achieve the best outcome. The rational approach encompasses the syllogism and Turing-test approaches. We still need provably correct inference and the formal representations of logic as well as the ability to perceive, communicate, and learn to achieve a good outcome. But we need to generalize these approaches to include \u0026ldquo;good-enough\u0026rdquo; inference and adaptation to the changing environment contexts that the agent is facing without giving up on the mathematical formality that utility theory allows us to design such agents.\nThe agent facing a fire is an instructive example. There maybe no time for optimal reasoning to a conclusion (e.g. run) but a simple reflexive plan can offer the best outcome.\nAI as a distributed system approach As its evident from all existing approaches towards AI, multidisciplinary science that aims to create agents that can think and act humanly or rationally. This course starts the new decade filled with the promises of the previous one - AI is not only around the corner and it can take several decades of R\u0026amp;D for it to match human intelligence. Our purpose here is to (a) understand and appreciate the significant progress that certain components of AI have made over the last few years and (b) to be able to synthesize such components into AI systems that can at least solve domain-specific problems. In other words we are not trying to solve the most difficult and general AI problem as we don\u0026rsquo;t know its solution. We also can\u0026rsquo;t wait as we would like to participate in the GAI developments to begin with.\nA substantial part of AI is machine learning (ML) and that component alone is worth of at least a couple semesters. ML nowadays is used to process the visual sensing (computer vision), verbal commands (speech to text) and many other front-end functions using structures known as Deep Neural Networks (DNNs). These functions are usually effective in modeling the reflexive part of human brain. Their performance sometimes hides the enormous efforts by R\u0026amp;D teams to create carefully curated datasets for the task at hand. When supervised datasets are not enough for the design of reflexive agents policies, we need additional tools such as Deep Reinforcement Learning that offer the possibility to learn agent control policies from world models (or even without them) that in many instances means spending considerable time simulating the environment.\nAI is a system with the ability to represent the world and abstract concepts at multiple levels. If we are to draw the architecture of such system, it will have the ability to quickly change depending on the domain and task at hand. Just like origami, AI systems will morph into a suitable architecture, facilitated by high speed interconnections between its subsystems. The controller that controls such changes must be topology aware i.e. knowing the functional decomposition of the AI system and what support for representations and abstractions each subsystem can offer. How these can be combined and ultimately used, is something that needs to be learned. To generalize, such morphic control agents must be able to perform across task domains.\nAI distributed system comprising from a number of high-speed interconnected subsystems that are loosely coupled and communicate via a universal language. Line thickness indicates stronger coupling / dependecies between subsystems for the task at hand at this moment in time.\nIn a limited demonstration of such ability, closed worlds such as games, we have agents that can process thousands of pixels and can create abstractions at the symbolic level. Are they able to generalize ? Doubtful. Which brings us to the very interesting thought. For the vast majority of mission critical industries, we may reach in this decade a good enough performance level. The internet didn\u0026rsquo;t have 1 Gbps at each household even 5 years ago. But the moment we crossed the 1 Mbps level per user, at the hands of innovators, it managed to change the world as we know it despite its many initial performance issues. The internet does not kill, many people will argue but if anyone believes this analogy, todays\u0026rsquo; AI architecture, a bunch of service-oriented silos (APIs) offered by major technology firms, resembles the disconnected/siloed PC before the invention of HTTP and the internet era of the 90s. The protocol and controls that will allow such AI systems to communicate and by doing so demonstrate an ability to synthesize a non-trivial version of intelligence is one of the missing links.\nThe architecture of serf-driving cars in the late 2010s. To avoid wondering around the various disconnected use cases, we need to pick a domain that we can use as an application theme. Given the importance of the mission critical industries in the economy of every country, in this course we have selected robotics / self-driving cars. This domain requires the design of advanced agents that perceive the environment using noisy sensors, make decisions under uncertainty, actuate a host of electronics to execute decisions, communicate with humans in natural language or be able to sense driver psychological state and many more.\n"});index.add({'id':4,'href':'/cs-gy-6613-spring-2020/docs/lectures/ai-intro/','title':"Week 1 - Introduction to AI",'content':" Summary of the Lecture and Action Items Action Items Technical  Read Chapters 1 and 2 of the AIMA book. Set up your programming environment following the Projects -\u0026gt; Setup guide.  Administrative  Join Slack workplace that was sent to you by gmail. Fill the form asking about your background.  "});index.add({'id':5,'href':'/cs-gy-6613-spring-2020/docs/lectures/ai-intro/ai-pipelines/','title':"The Way of Working in AI",'content':" A Positive Reinforcement Loop What are the disciplines that need to cross fertilize to get a system that possesses intelligence? Lets start with a diagram that show not only the disciplines but also a way of working for the many specialists involved.\nThe diagram above highlights three fundamental axes that can deliver a system-based approach to AI. The Z axis is the scientific axis where many disciplines such as psychology, neuroscience, mathematics and others make progress on. The X axis involves the ML/AI communities that borrow ideas from their colleagues in sciences and convert those theories and pragmatic findings into abstractions (models and methods). The model of the neuron, the perceptron, appeared in psychology journals many decades ago and despite its simplicity it is still the unit via which much more complicated neural networks are constructed from. Todays\u0026rsquo; models of Long-Term Short-Term Memory (LSTM), Replay Memory and many others not shown in the diagram (as its currently in draft form) are abstractions (models) of discoveries that scientists produced after tens of years of research. To use however these methods and models effectively, major hardware and software components need to be developed also known as computing and frameworks - these live in the Y axis. They are very important for the development of AI field that is known to be heavily experimental, requiring especially at the perceptive frontend significant computational power and automation.\nAt a very high level, progress in AI is made via the counterclockwise iteration Z -\u0026gt; X -\u0026gt; Y -\u0026gt; Z. AI engineers look at the neuroscience/psychology axis, map discoveries to points in the methods / models axis, and finally develop these methods in hardware architectures and software frameworks. But what can explain the Y -\u0026gt; Z flow? Frameworks in turn help the neuroscientists and psychologists as they can provide generative models of their own discoveries or help them simulate conditions that are not possible using their native tools.\nThis counter-clockwise multidisciplinary iteration acts as a positive feedback loop accelerating the progress in the AI space.\nIn this course we will be focusing on the methods/models and frameworks axis and understand what these models can offer us and how we can apply them in synthesizing an AI system at least for a domain of interest.\nA typical AI stack today As we have seen from the syllabus, this course approaches AI from an applied perspective - this means teaching concepts but at the same time looking how these concepts are applied in the industry to solve real world problems. In this respect here we take an architecture driven AI, presenting the components of AI in a form of a software stack but also how the components are mechanized in what we call ML Pipelines to provide the ML utility to applications. For a complete overview of real world ML pipelines used today go through the TFX paper in its entirety.\nAI Stack circa 2019\nLandscape of the AI ecosystem Due to the complexity and common interest to addresses industrial players are partnering to define and implement the necessary components for the complete automation of AI pipelines. This work is going in within the Linux Foundation AI (sub)Foundationamongst many other open source communities.\n   The four pipelines of an end-to-end ML platform Example of end to end pipeline - serial arrangement\nExample of Data Pipeline\nExample of Model Training Pipeline\nExample of Model Evaluation and Validation Pipeline\nExample of Serving Pipeline\nRoles in AI product development Who data scientists need to interact with, during the development of AI systems?\n \u0026ldquo;Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization\u0026rsquo;s communication structure.\u0026rdquo; http://www.melconway.com/Home/Conways_Law.html\n \u0026ldquo;We do research differently here at Google. Research Scientists aren\u0026rsquo;t cloistered in the lab, but instead they work closely with Software Engineers to discover, invent, and build at the largest scale.\u0026rdquo;\nContrast this to an organizational structure that isolates researchers from product development. What about Alphabet\u0026rsquo;s X https://x.company/ ?\n"});index.add({'id':6,'href':'/cs-gy-6613-spring-2020/docs/lectures/ai-intro/agents/','title':"Intelligent Agents and Representations",'content':""});index.add({'id':7,'href':'/cs-gy-6613-spring-2020/docs/projects/','title':"Projects",'content':"The following projects needs to be delivered by the deadlines.\n Surface Type Classification - Due 2/23/2020 11:59pm Lifelong Learning - Robotic Vision - Due 3/29/2020 11:59pm TBD - Due 5/10/2020 11:59pm  "});index.add({'id':8,'href':'/cs-gy-6613-spring-2020/docs/lectures/ml-math/','title':"Background - Math for ML",'content':""});index.add({'id':9,'href':'/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/','title':"Background - ML Frameworks",'content':" The Zillow App The Zillow app is based on the end to end machine learning example in Chapter 2 of Geron\u0026rsquo;s book. We can go through this end to end example during a recitation.\nAlthough the ML project checklist provided in Appendix B of Garon\u0026rsquo;s book is extensive (we will go through this list in the lecture as we go through your first ML application) for now focus on the eight steps as shown below.\nSteps in workflow (from here)\n As discussed the data pipeline is responsible for providing the training datasets if the aim is to train (or retrain) a model. For the purposes of this lecture we assume that we deal with small data aka. data fit in the memory of today\u0026rsquo;s typical workstations/laptops (\u0026lt; 16 GB). Therefore you will be given a URL from where compressed data files can be downloaded. For structured data, these files when uncompressed will be typically CSV. For unstructured they will be in various formats depending on the use case. In most instances, ML frameworks that implement training will require certain transformations to optimize the format for the framework at hand (see TFrecords in tensorflow).\n Appendix B of Garon\u0026rsquo;s book goes into more detail on the steps suggested to be followed in an end to end ML project.\n Key Questions  Is the dataset appropriate for training?   Any unexpected ranges, any range heterogeneity, any clipping? Do we face long-tails? What options do we have to glean the data?\n  What will happen if we remove the following line from the split_train_set function?\nshuffled_indices = np.random.permutation(len(data))  "});index.add({'id':10,'href':'/cs-gy-6613-spring-2020/docs/lectures/ai-intro/ai-pipelines/ai-pipelines-slides/','title':"Ai Pipelines Slides",'content':""});index.add({'id':11,'href':'/cs-gy-6613-spring-2020/categories/','title':"Categories",'content':""});index.add({'id':12,'href':'/cs-gy-6613-spring-2020/','title':"CS-GY-6613 Artificial Intelligence - Spring 2020",'content':" Welcome to CS-GY-6613 ! Logistics Time/location: Brooklyn Campus, Mon 6.00 PM - 8.30 PM at RGSH 315.\nCommunication: We will use Slack for all communications: announcements and questions related to lectures, assignments, and projects. All registered students got an gmail invitation to Slack on 1/28/2020.\nInstructor Pantelis Monogioudis, Ph.D (Bell Labs) Head of Applied ML Research Group Murray Hill, NJ\nTeaching Assistants TA\u0026rsquo;s contact will be announced as soon as I receive confirmation from HR that were hired. I am targeting two TAs for this class.\nWhat is this course about This course is all about the algorithms and methods that will enable agents that exhibit forms of intelligence and autonomy.\nGrading  Final (30%) Midterm (30%) Projects (40%)  "});index.add({'id':13,'href':'/cs-gy-6613-spring-2020/docs/','title':"Docs",'content':""});index.add({'id':14,'href':'/cs-gy-6613-spring-2020/docs/lectures/ml-frameworks/tensorflow-introduction/','title':"Introduction to Tensorflow",'content':"This by no means is a tutorial introduction but rather a set of slides that we can use to describe the principle of computational graphs. This can be skipped and consulted later in the course.\nWe will cover slides #1 - #28 as shown below. The slides are from CS 20: Tensorflow for Deep Learning Research and despite the title are appropriate for Tensorflow beginners. Slides beyond #28 will be selectively consulted when we go over gradients and backpropagation.\n "});index.add({'id':15,'href':'/cs-gy-6613-spring-2020/docs/lectures/ml-math/linear-algebra/','title':"Linear Algebra for Machine Learning",'content':" Linear Algebra for Machine Learning The corresponding chapter of Ian Goodfellow\u0026rsquo;s Deep Learning is essentially the background you need.\n Key Points We can now summarize the points to pay attention to for ML applications. In the following we assume a data matrix $A$ with \\(m\\) rows and $n$ columns. We also assume that the matrix is such that it has $r$ independent rows, called the matrix rank.\nThe Four Fundamental Subspaces The fundamental theorem of Linear Algebra specifies the effect of the multiplication operation of the matrix and a vector ($A\\mathbf{x}$). The matrix gives raise to 4 subspaces:\n The column space of $A$, denoted by $\\mathcal{R}(A)$, with dimension $r$. The nullspace of $A$, denoted by $\\mathcal{N}(A)$, with dimension $n-r$. The row space of $A$ which is the column space of $A^T$, with dimension $r$ The left nullspace of $A$, which is the nullspace of $A^T$, denoted by $\\mathcal{N}(A^T)$, with dimension $m-r$.  The real action that the matrix perform is to transform its row space to its column space.\nThe type of matrices that are common in ML are those that the number of rows $m$ representing observations is much larger than the number of columns $n$ that represent features. We will call these matrices \u0026ldquo;tall\u0026rdquo; for obvious reasons. Let us consider one trivial but instructive example of the smallest possible \u0026ldquo;tall\u0026rdquo; matrix:\n  \\( \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\\\ a_{31} \u0026 a_{32} \\end{bmatrix} = \\begin{bmatrix} 1 \u0026 0 \\\\ 5 \u0026 4 \\\\ 2 \u0026 4 \\end{bmatrix} \\)  In ML we are usually concerned with the problem of learning the weights $x_1, x_2$ that will combine the features and result into the given target variables $\\mathbf{b}$. The notation here is different and we have adopted the notation of many linear algebra textbooks.\n \\( \\begin{bmatrix} 1 \u0026 0 \\\\ 5 \u0026 4 \\\\ 2 \u0026 4 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\)  To make more explicit the combination of features we can write,\n\\( x_1 \\begin{bmatrix} 1 \\\\ 5 \\\\ 2 \\end{bmatrix} + x_2 \\begin{bmatrix} 0 \\\\ 4 \\\\ 4 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\)  Since $m=3 \u0026gt; n=2$, we have more equations than unknowns we in general we have no solutions - a system with $m \u0026gt; n$ will be solvable only for certain right hand sides $\\mathbf{b}$. Those are all the vectors $\\mathbf{b}$ that lie in the column space of $A$.\nIn this example, as shown in the picture $\\mathbf{b}$ must lie in the plane spanned by the two columns of $A$. The plane is a subspace of $\\mathbb{R}^m=\\mathbb{R}^3$ in this case.\nNow instead of looking at what properties $\\mathbf{b}$ must have for the system to have a solution, lets look at the dual problem i.e. what weights $\\mathbf{x}$ can attain those $\\mathbf{b}$. The right-hand side $\\mathbf{b}=0$ always allows the solution $\\mathbf{x}=0$ The solutions to $A \\mathbf{x} = \\mathbf{0}$ form a vector space - the nullspace $\\mathcal{N}(A)$. The nullspace is also called the kernel of matrix $A$ and the its dimension $n-r$ is called the nullity.\n$\\mathcal{N}(A)$ is a subspace of $\\mathbb{R}^n=\\mathbb{R}^2$ in this case. For our specific example,\n\\( x_1 \\begin{bmatrix} 1 \\\\ 5 \\\\ 2 \\end{bmatrix} + x_2 \\begin{bmatrix} 0 \\\\ 4 \\\\ 4 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix} \\)  the only solution that can satisfy this set of homogenous equations is: $\\mathbf{x}=\\mathbf{0}$ and this means that the null space contains only the zero vector and this\nTwo vectors are independent when their linear combination cannot be zero, unless both $x_1$ and $x_2$ are zero. The columns of $A$ are therefore linearly independent and they span the column space. They have therefore all the properties needed for them to constitute a set called the basis for that space and we have two basis vectors (the rank is $r=2$ in this case). The dimension of the column space is in fact the same as the dimension of the row space ($r$) and the mapping from row space to column space is in fact invertible. Every vector $\\mathbf{b}$ comes from one and only one vector $\\mathbf{x}$ of the row space ($\\mathbf{x}_r$). And this vector can be found by the inverse operation - noting that only the inverse $A^{-1}$ is the operation that moves the vector correctly from the column space to the row space. The inverse exists only if $r=m=n$ - this is important as in most ML problems we are dealing with \u0026ldquo;tall\u0026rdquo; matrices with the number of equations much larger than the number of unknowns which makes the system inconsistent (or degenerate).\nProjection onto the column space\nGeometrically you can think about the basis vectors as the axes of the space. However, if the axes are not orthogonal, calculations will tend to be complicated not to mention that we usually attribute to each vector of the basis to have length one (1.0).\nEigenvalues and Eigenvectors The following video gives an intuitive explanation of eigenvalues and eigenvectors and its included here due to its visualizations that it offers. The video must be viewed in conjunction with Strang\u0026rsquo;s introduction\n During the lecture we will go through an example from how your brain processes the sensory input generated by the voice of the lecturer(unless you are already asleep by that time) to combine optimally the sound from both your ears.\nA geometric interpretation of the eigenvectors and eigenvalues is given in the following figure:\n"});index.add({'id':16,'href':'/cs-gy-6613-spring-2020/docs/lectures/ml-math/optimization/','title':"Optimization and Stochastic Gradient Descent",'content':" Optimization and Stochastic Gradient Descent In this lecture we will go over concepts from Ian Goodfellow\u0026rsquo;s chapter 4 below. Stochastic gradient descent is treated also in section 5.9.\n "});index.add({'id':17,'href':'/cs-gy-6613-spring-2020/docs/lectures/ml-math/probability/','title':"Probability and Information Theory Basics",'content':" Book Chapters From Ian Goodfellow\u0026rsquo;s book: \nWe will go through the main points during the lecture and treat also MacKay\u0026rsquo;s book (Chapter 2) that is also instructive and a much better in introducing probability concepts. If you are a visual learner, the visual information theory blog post is also a good starting point.\nKey Concepts to understand Probability The pictures below are from MacKays book and despite their conceptual simplicity they hide many questions that we will go over the lecture.\nProbability distributions Probability distribution over the letters of the English alphabet (letter 27 symbolizes space)\nJoint probability distributions Joint probability $P(x,y)$ distribution over the 27x27 possible bigrams $xy$ found in this document: https://www.tldp.org/FAQ/pdf/Linux-FAQ.pdf\nWhat is the marginal probability $P(x)$ ?\nConditional probability distribution\nConditional probability distribution over the 27x27 possible bigrams $xy$ found in this document: https://www.tldp.org/FAQ/pdf/Linux-FAQ.pdf\nAre $x$ and $y$ independent ?\nProbability Rules If H is the hypothesis governing the probabilities distributions,\nProduct or chain rule:\nThis is obtained from the definition of conditional probability:\n$P(x,y|H) = P(x | y,H)P(y | H) = P(y | x,H)P(x |H)$\nSum rule:\nThis is obtaining by rewriting of the marginal probability denition: $P(x |H) = \\sum_y P(x,y |H) = \\sum_y P(x | y,H)P(y |H)$\nKey probability distributions Multi-variate Gaussian distribution $$f_{\\mathbf X}(x_1,\\ldots,x_k) = \\frac{\\exp\\left(-\\frac 1 2 ({\\mathbf x}-{\\boldsymbol\\mu})^\\mathrm{T}{\\boldsymbol\\Sigma}^{-1}({\\mathbf x}-{\\boldsymbol\\mu})\\right)}{\\sqrt{(2\\pi)^n|\\boldsymbol\\Sigma|}}$$ where where \u0026lt;${\\mathbf x}$ is a real \u0026lsquo;n\u0026rsquo;-dimensional column vector and $|\\boldsymbol\\Sigma|\\equiv \\operatorname{det}\\boldsymbol\\Sigma$ is the determinant of $\\boldsymbol\\Sigma$.\nApart from the definition, you need to connect the geometric interpretation of the bivariate Gaussian distribution to the eigendecomposition in the linear algebra lecture as shown in the Figure 2.7 of Bishop:\nSuch geometric interpretations will be very useful when we study dimensionality reduction via Principal Component Analysis (PCA).\nProbabilistic Modeling  The whole purpose of probabilistic modeling is to introduce uncertainty into our problem statement. There are three types of uncertainties:\n Inherent stochasticity - e.g. impact of wind in self-driving car control systems at moderate to high speed. Incomplete observability - e.g. sensor imperfections causing loss of sensing information Incomplete modeling - e.g. models and algorithms that are not implementable to an analog world and need to be discretized.  Probabilities can be used in two ways.\n Probabilities can describe frequencies of outcomes in random experiments Probabilities can also be used, more generally, to describe degrees of belief in propositions that do not involve random variables. This more general use of probability to quantify beliefs is known as the Bayesian viewpoint. It is also known as the subjective interpretation of probability, since the probabilities depend on assumptions.  The Bayesian theorem is the cornerstone of probabilistic modeling. If $\\mathbf{\\theta}$ denotes the unknown parameters, $D$ denotes the dataset and $\\mathcal{H}$ denotes the hypothesis space - the model we have seen in the ML problem statement section.\n   $$ P(\\mathbf{\\theta} | D, \\mathcal{H}) = \\frac{P( D | \\mathbf{\\theta}, \\mathcal{H}) P(\\mathbf{\\theta} | \\mathcal{H}) }{ P(D|\\mathcal{H}} $$\nThe Bayesian framework allows the introduction of priors from a wide variety of sources (experts, other data, past posteriors, etc.) For example,a medical patient is exhibiting symptoms x, y and z. There are a number of diseases that could be causing all of them, but only a single disease is present. A doctor (the expert) has beliefs about which disease, but a second doctor may have slightly different beliefs.\nNOTE: The Probabilistic Programming \u0026amp; Bayesian Methods for Hackers book is one of the best resources out there containing practical python examples. In addition they have been recoded recently to work in Tensorflow Probability an industrial-strength framework that can bring together Deep Learning and domain-specific probabilistic modeling. The book cant match the rigorousness of Bishop\u0026rsquo;s book but it offers a good treatment on problems and use cases and should be considered complimentary.\n Bayesian update example  -- This example is instructive beyond the habit of having coin flip examples in every textbook in probability theory and statistics. It is useful to understand the conjugate prior distribution being discussed in Bishop\u0026rsquo;s section 2.1.1 and Figure 3 that the code above replicates. Armed with this understanding, we can now treat the Bayesian update for linear regression as described in the linear regression section.\nInformation-theoretic definitions Entropy An outcome $x_t$ carries information that is a function of the probability of this outcome $P(x_t)$ by,\n$I(x_t) = \\ln \\frac{1}{P(x_t)} = - \\ln P(x_t)$\nThis can be intuitively understood when you compare two outcomes. For example, consider someone is producing the result of the vehicular traffic outside of Holland tunnel on Monday morning. The information that the results is \u0026ldquo;low\u0026rdquo; carries much more information when the result is \u0026ldquo;high\u0026rdquo; since most people expect that there will be horrendous traffic outside of Holland tunnel on Monday mornings. When we want to represent the amount of uncertainty over a distribution (i.e. the traffic in Holland tunnel over all times) we can take the expectation over all possible outcomes i.e.\n$H(P) = - \\mathbb{E} \\ln P(x)$\nand we call this quantity the entropy of the probability distribution $P(x)$. When $x$ is continuous the entropy is known as differential entropy. Continuing the alphabetical example, we can determine the entropy over the distribution of letters in the sample text we met before as,\nThis is 4.1 bits (as the $\\log$ is taken with base 2). This represents the average number of bits required to transmit each letter of this text to a hypothetical receiver. Note that we used the information carried by each \u0026ldquo;outcome\u0026rdquo; (the letter) that our source produced. If the source was binary, we can plot the entropy of such source over the probability p that the outcome is a 1 as shown below,\nThe plot simply was produced by taking the definition of entropy and applying to the binary case,\n$H(p) = - [p \\ln p - (1-p) \\ln(1-p)]$\nAs you can see the maximum entropy is when the outcome is most unpredictable i.e. when a 1 can show up with uniform probability (in this case equal probability to a 0).\nRelative entropy or KL divergence (optional) In the ML problem statement, it is evident that the job of the learning algorithm is to come up with a final hypothesis that is close to the unknown target function. In other occasions, we need to approximate a distribution by sampling from another easier to model distribution. As in ML we work with probabilities, we need to have a metric that compares two probability distributions ${P(x),Q(x)}$ in terms of their \u0026ldquo;distance\u0026rdquo; from each other (the quotes will be explained shortly). This is given by the quantity known as relative entropy or KL divergence.\n$KL(P||Q)= \\mathbb{E}[\\ln P(x) - \\ln Q(x)]$\nIf the two distributions are identical, $KL=0$ - in general however $KL(P||Q) \\ge 0$. One key element to understand is that $KL$ is not a true distance metric as its assymetric. Ensure that you understand fully the following figure and caption.\nVery close to the relative entropy is probably one of the most used information theoretic concepts in ML: the cross-entropy. We will motivate cross entropy via a diagram shown below,\nBackground for logistic regression If $\\sigma$ is a probability of an event, then the ratio $\\frac{\\sigma}{1-\\sigma}$ is the corresponding odds, the ratio of the event occurring divided by not occurring. For example, if a race horse runs 100 races and wins 25 times and loses the other 75 times, the probability of winning is 25\u0026frasl;100 = 0.25 or 25%, but the odds of the horse winning are 25\u0026frasl;75 = 0.333 or 1 win to 3 loses. In the binary classification case, the log odds is given by\n$$ \\mathtt{logit}(\\sigma) = \\alpha = \\ln \\frac{\\sigma}{1-\\sigma} = \\ln \\frac{p(\\mathcal{C}_1|\\mathbf{x})}{p(\\mathcal{C}_2|\\mathbf{x})}$$\nWhat is used in ML though is the logistic function of any number $\\alpha$ that is given by the inverse logit:\n$$\\mathtt{logistic}(\\alpha) = \\sigma(\\alpha) = \\mathtt{logit}^{-1}(\\alpha) = \\frac{1}{1 + \\exp(-\\alpha)} = \\frac{\\exp(\\alpha)}{ \\exp(\\alpha) + 1}$$\nand is plotted below. It maps its argument to the \u0026ldquo;probability\u0026rdquo; space [0,1].\nLogistic sigmoid (red)\nThe sigmoid function satisfies the following symmetry:\n$$\\sigma(-\\alpha) = 1 - \\sigma(\\alpha)$$\nIn addition it offers very convenient derivatives and has been used extensively in deep neural networks (for many architectures has been superceded by RELU). The derivative can be obtained as follows:\nConsider $$ f(x)=\\dfrac{1}{\\sigma(x)} = 1+e^{-x} . $$ Then, on the one hand, the chain rule gives $$ f\u0026rsquo;(x) = \\frac{d}{dx} \\biggl( \\frac{1}{\\sigma(x)} \\biggr) = -\\frac{\\sigma\u0026rsquo;(x)}{\\sigma(x)^2} , $$ and on the other hand, $$ f\u0026rsquo;(x) = \\frac{d}{dx} \\bigl( 1+e^{-x} \\bigr) = -e^{-x} = 1-f(x) = 1 - \\frac{1}{\\sigma(x)} = \\frac{\\sigma(x)-1}{\\sigma(x)} $$\nEquating the two expressions we finally obtain,\n$$\\sigma\u0026rsquo;(x) = \\sigma(x)(1-\\sigma(x))$$\n"});index.add({'id':18,'href':'/cs-gy-6613-spring-2020/docs/projects/imu-classification/','title':"Project 1 - Surface Type Classification",'content':" Project 1 - Surface Type Classification  Your first project description is published in https://www.kaggle.com/c/career-con-2019/overview\n You must submit your assignment with the results by 11:59pm 2/23/2020. The submission will be done by sharing the github/kaggle notebook with the TA.\n  "});index.add({'id':19,'href':'/cs-gy-6613-spring-2020/docs/projects/continuous-learning/','title':"Project 2 - Continual Learning for Robotic Perception",'content':" Project 2 - Continual Learning for Robotic Perception One of the greatest goals of AI is building an artificial continual learning agent which can construct a sophisticated understanding of the external world from its own experience through the adaptive, goal-oriented and incremental development of ever more complex skills and knowledge. Continual learning is essential in robotics where high dimensional data streams need to be constantly processed and where naïve continual learning strategies have been shown to suffer from catastrophic forgetting.\nYou will use this dataset and evaluate your methods for New Classes (NC) scenario. This is a very active area in AI right now - see here\n"});index.add({'id':20,'href':'/cs-gy-6613-spring-2020/docs/projects/project-3/','title':"Project 3",'content':""});index.add({'id':21,'href':'/cs-gy-6613-spring-2020/tags/','title':"Tags",'content':""});index.add({'id':22,'href':'/cs-gy-6613-spring-2020/docs/lectures/ml-math/netflix/','title':"The Netflix Prize and Singular Value Decomposition",'content':" Introduction The following are based on the winning submission paper as well as their subsequent publication.\nThe Netflix Prize was an open competition for the best collaborative filtering algorithm to predict user ratings for films, based on previous ratings without any other information about the users or films, i.e. without the users or the films being identified except by numbers assigned for the contest.\nThe competition was held by Netflix, an online DVD-rental and video streaming service, and was open to anyone who is neither connected with Netflix (current and former employees, agents, close relatives of Netflix employees, etc.) nor a resident of certain blocked countries (such as Cuba or North Korea).[1] On September 21, 2009, the grand prize of US \\$ 1,000,000 was given to the BellKor\u0026rsquo;s Pragmatic Chaos team which bested Netflix\u0026rsquo;s own algorithm for predicting ratings by 10.06\\%\nThis competition is instructive since:\n Collaborative filtering models try to capture the interactions between users and items that produce the different rating values. However, many of the observed rating values are due to effects associated with either users or items, independently of their interaction. A prime example is that typical CF data exhibit large user and item biases – i.e., systematic tendencies for some users to give higher ratings than others, and for some items to receive higher ratings than others. Observing the posted improvements in RMSE over time, the competition has become of little business value to Netflix after a while. This means that it was unlikely that any minute improvement to RMSE (e.g. 0.1%) will translate to additional revenue. The 10% improvement goal was a lucky number after all. Netflix had no clue as to if this was the right number when they defined the terms. Any small deviation from this number, would have made the competition either too easy or impossibly difficult.  Problem statement You are given the following dataset structure (will be explained in class) shown below,\nAssuming that the rating matrix A is an m x n matrix with m users (500K) and n items (17K movies), this matrix is extremely sparse - it has only 100 million ratings, the remaining 8.4 billion ratings are missing (about 99% of the possible ratings are missing, because a user typically rates only a small portion of the movies).\nGiven the very large data matrix it was only expected that competitors attempted to work out some form of dimensionality reductions and as it turns out this was the basis for the winning algorithm. If you recall the premise of SVD from linear algebra, it is a decomposition that can work with rectangular matrices and can result into a decomposition of the following kind:\n$$A = U \\Sigma V^†$$\nwhere $\\mathbf{U}$ is a $m \\times m$ real unitary matrix, $\\mathbf{\\Sigma}$ is an $m \\times n$ rectangular diagonal matrix with non-negative real numbers on the diagonal, and $\\mathbf{V}$ is a $n \\times n$ real unitary matrix. Remember that a unitary matrix $U$ is a matrix that its conjugate transpose $U^†$ is also its inverse - its the complex analog of the orthogonal matrix and we have by definition $UU^†=I$.\nThe columns of $U$ are eigenvectors of $AA^T$, and the columns of $V$ are eigenvectors of $A^TA$. The $r$ singular values on the diagonal of $\\Sigma$ are the square roots of the nonzero eigenvalues of both $AA^T$ and $A^TA$.\nIt is interesting to attribute the columns of these matrices with the four fundamental subspaces:\n The column space of $A$ is spanned by the first $r$ columns of $U$. The left nullspace of $A$ are the last $m-r$ columns of $U$. The row space of $A$ are the first $r$ columns of $V$. The nullspace of $A$ are the last $n-r$ columns of V.  We can write the SVD as,\n$$A = U \\sqrt{\\Sigma} \\sqrt{\\Sigma} V^†$$\nand given the span of the subspaces above we can now intuitively think what the terms $\\mathbf{p}_u = U \\sqrt{\\Sigma}$ and $\\mathbf{q}_i = \\sqrt{\\Sigma} V^†$ represent.\nSVD decomposition reveals latent features weighted by the underlying singular values of the data matrix\nThe first term represents the column space aka. it provides a representation of all inter-user factors (also called latent features, latent means hidden). The second term represents the row space aka. it provides a representation of all inter-movie factors. Which brings us to the major point of what the $\\sqrt{\\Sigma}$ is doing to both terms. It represents the significance of those factors and therefore we can very easily use the singular values it contains to \u0026ldquo;compress\u0026rdquo; our representation by selecting the $k$ largest singular values and ignoring the rest.\nGiven these vectors of factors we can now use them to predict the rating:\n*Prediction of a rating is the product between user latent features and movie latent features matrices.\nFor an intuitive description of the SVD solution see here.\n"});index.add({'id':23,'href':'/cs-gy-6613-spring-2020/docs/projects/env/','title':"Your Programming Environment",'content':" Your Programming Environment Starting Jupyter in Google Colab The runtime performance will greatly improve for some projects using the free GPU resources provided by Google Colab. In this course we will make use of these facilities - the good news is that you have an account in Google Colab as most of you have a google account. If not go ahead and create one to be able to login into Google colab. You will need Google Colab for all your projects so that you can demonstrate that your results can be replicated. In addition Colab has many features that come handy.\nI heavily borrowed from Geron\u0026rsquo;s book for the following.\nSetup Anaconda Python When using Anaconda, you need to create an isolated Python environment dedicated to this course. This is recommended as it makes it possible to have a different environment for each project, with potentially different libraries and library versions:\n$ conda create -n cs6613 python=3.6 anaconda $ conda activate cs6613 This creates a fresh Python 3.6 environment called cs6613 (you can change the name if you want to), and it activates it. This environment contains all the scientific libraries that come with Anaconda. This includes all the libraries we will need (NumPy, Matplotlib, Pandas, Jupyter and a few others), except for TensorFlow, so let\u0026rsquo;s install it:\n$ conda install -n cs6613 -c conda-forge tensorflow This installs the latest version of TensorFlow available for Anaconda (which is usually not the latest TensorFlow version) in the cs6613 environment (fetching it from the conda-forge repository). If you chose not to create an cs6613 environment, then just remove the -n cs6613 option.\nNext, you can optionally install Jupyter extensions. These are useful to have nice tables of contents in the notebooks, but they are not required.\n$ conda install -n cs6613 -c conda-forge jupyter_contrib_nbextensions Kaggle Assuming you have activated the cs6613 conda environment, follow the directions here to install the Kaggle command line interface (CLI). You will need Kaggle for all your projects. You guessed it right - all the projects in this course are in fact Kaggle competitions. Not only you will get to compete (your ranking relative to others does not matter per se), but as you improve your knowledge over time you can revisit these competitions and see how your score improves.\nYou are all set! Next, jump to the Starting Jupyter section.\nStarting Jupyter locally If you want to use the Jupyter extensions (optional, they are mainly useful to have nice tables of contents), you first need to install them:\n$ jupyter contrib nbextension install --user Then you can activate an extension, such as the Table of Contents (2) extension:\n$ jupyter nbextension enable toc2/main Okay! You can now start Jupyter, simply type:\n$ jupyter notebook This should open up your browser, and you should see Jupyter\u0026rsquo;s tree view, with the contents of the current directory. If your browser does not open automatically, visit localhost:8888. Click on index.ipynb to get started!\nNote: you can also visit http://localhost:8888/nbextensions to activate and configure Jupyter extensions.\nGit / Github Git is the defacto standard when it comes to code version control. Learning basic git commands takes less than half an hour. However, to install git and understand the principle behind git, please go over Chapters 1 and 2 of the ProGit book.\nAs we have discussed in class you need to be able to publish your work in Github so you need to create a Github account. Then you will use the git client for your operating system to interact with github and iterate on your projects. You may be using Kaggle or Colab hosted notebooks but the underlying technology that powers such web-frontends when it comes to committing the code and seeing version numbers in your screen is git.\nIn addition, almost no data science project starts in vacuum - there is almost always software that will be inherited to be refined.\n"});})();